{"cells":[{"cell_type":"markdown","source":["---\n","\n","TensorFlow [introduction to graphs](https://www.tensorflow.org/guide/intro_to_graphs)\n","\n","Graphs are data structures that contain a set of tf.Operation objects, which represent units of computation; and tf.Tensor objects, which represent the units of data that flow between operations. They are defined in a tf.Graph context. Since these graphs are data structures, they can be saved, run, and restored all without the original Python code for example on embedded devices, servers etc that not have built-in Python interpreters. Graphs can also be optimized to run faster.\n","\n","<img src = 'https://drive.google.com/uc?id=1Q8-9CJbEZez8oOU0K-_sHQ-tDNgj8CAQ' alt = \"graph components\" width=\"400\">\n","<img src = 'https://drive.google.com/uc?id=1Q7_c8CXV8_eEvPbNyAjdUN1tXCFKUS0e' alt = \"graph\" width=\"400\">\n","\n","\n","---"],"metadata":{"id":"tNMQnzrDTAob"},"id":"tNMQnzrDTAob"},{"cell_type":"code","execution_count":37,"id":"valued-lodging","metadata":{"id":"valued-lodging","executionInfo":{"status":"ok","timestamp":1709122468801,"user_tz":-330,"elapsed":478,"user":{"displayName":"S N S Acharya","userId":"14786945180387920086"}},"outputId":"957c9989-8b64-4ad1-d780-90439d1c1631","colab":{"base_uri":"https://localhost:8080/","height":35}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.15.0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":37}],"source":["import numpy as np\n","import timeit\n","import matplotlib.pyplot as plt\n","plt.style.use('dark_background')\n","%matplotlib inline\n","\n","import tensorflow as tf\n","tf.__version__"]},{"cell_type":"markdown","source":["---\n","\n","**TensorFlow eager execution**: tensor computations are executed by Python, operation by operation, and return results back to Python.\n","\n","**TensorFlow graph execution**: tensor computations are executed as a TensorFlow graph, sometimes referred to as a tf.Graph or simply a \"graph.\"\n","\n","Graph execution enables portability outside Python and tends to offer better performance.  \n","\n","\n","---"],"metadata":{"id":"zacewfWuTx_n"},"id":"zacewfWuTx_n"},{"cell_type":"code","source":["# Define a function in Python\n","def a_func_in_python(x, y, b):\n","  x = tf.matmul(x, y)\n","  x = x + b\n","  return x\n","\n","# A function that uses a graph version of the function above\n","a_func_that_uses_graph = tf.function(a_func_in_python)\n","\n","# Make some tensors.\n","x1 = tf.constant([[1.0, 2.0, 3.0]])\n","y1 = tf.constant([[1.0], [2.0], [3.0]])\n","b1 = tf.constant(4.0)\n","\n","# Call the two versions of the same function on the inputs\n","python_way = a_func_in_python(x1, y1, b1).numpy()\n","tf_function_way = a_func_that_uses_graph(x1, y1, b1).numpy()\n","\n","# Check if the two versions return the same output\n","print(python_way)\n","print(tf_function_way)"],"metadata":{"id":"B2VpALYvOBoG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709119056847,"user_tz":-330,"elapsed":441,"user":{"displayName":"S N S Acharya","userId":"14786945180387920086"}},"outputId":"8d31676e-c72b-4a6d-a001-9320e223b58c"},"id":"B2VpALYvOBoG","execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["[[18.]]\n","[[18.]]\n"]}]},{"cell_type":"markdown","source":["---\n","\n","tf.function applies to nested function calls\n","\n","---"],"metadata":{"id":"CijOHRNvb6da"},"id":"CijOHRNvb6da"},{"cell_type":"code","source":["# Inner function\n","def inner_function(x, y, b):\n","  x = tf.matmul(x, y) + b\n","  return x\n","\n","# Outer function that is converted into a graph\n","@tf.function\n","def outer_function(x):\n","  y = tf.constant([[1.0], [2.0], [3.0]])\n","  b = tf.constant(1.0)\n","  temp = inner_function(x, y, b)\n","  return(temp)\n","\n","# Calling the outer function will result in a\n","# graph that will also include the inner function's\n","# graph\n","outer_function(tf.constant([[1.0, 2.0, 3.0]])).numpy()"],"metadata":{"id":"S6KAF3aJb_i5"},"id":"S6KAF3aJb_i5","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","Converting Python functions with branches into graphs.\n","\n","---"],"metadata":{"id":"1tdtp9vudfyZ"},"id":"1tdtp9vudfyZ"},{"cell_type":"code","source":["def simple_relu(x):\n","  if tf.greater(x, 0):\n","    return x\n","  else:\n","    return 0\n","\n","# Function to wrap python function into a graph\n","tf_simple_relu = tf.function(simple_relu)\n","\n","print(\"First branch, with graph:\", tf_simple_relu(tf.constant(1)).numpy())\n","print(\"Second branch, with graph:\", tf_simple_relu(tf.constant(-1)).numpy())"],"metadata":{"id":"DVS7yPzUdoMp"},"id":"DVS7yPzUdoMp","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","Polymorphism using graphs\n","\n","<img src = 'https://drive.google.com/uc?id=1Q9rMsRHWtBVSaWMsmDX6UZS8l0Cfu4eh' alt = \"graph components\" width=\"400\">\n","\n","---"],"metadata":{"id":"ff0iTk_ZeLbx"},"id":"ff0iTk_ZeLbx"},{"cell_type":"code","source":["@tf.function\n","def my_relu(x):\n","  return tf.maximum(0., x)\n","\n","# Function creates a new graph for each case below\n","print(my_relu(tf.constant(1.0)))\n","print(my_relu([1, -1]))\n","print(my_relu(tf.constant([3., -3.])))\n","\n","# Function does not create a new graph for each\n","# case below because a graph has already been\n","# created above for the given data type and shape\n","print(my_relu(tf.constant(2.0)))\n","print(my_relu(tf.constant([1.5, -1.5])))"],"metadata":{"id":"t11Ha-JheYyA"},"id":"t11Ha-JheYyA","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","**Graph execution vs. eager execution**: the code in a tf.function can be executed both eagerly and as a graph. By default, tf.function executes its code as a graph.\n","\n","---"],"metadata":{"id":"SMUXPUiXfkum"},"id":"SMUXPUiXfkum"},{"cell_type":"code","source":["@tf.function\n","def get_MSE(y_true, y_pred):\n","  return tf.reduce_mean((y_true - y_pred)**2)\n","\n","y_true = tf.random.uniform([5], maxval=10, dtype=tf.int32)\n","y_pred = tf.random.uniform([5], maxval=10, dtype=tf.int32)\n","print(y_true)\n","print(y_pred)\n","\n","# Execution in graph mode\n","print(get_MSE(y_true, y_pred))\n","\n","# Switch of graph mode and turn on eager execution mode\n","tf.config.run_functions_eagerly(True)\n","print(get_MSE(y_true, y_pred))\n","\n","# Get back to graph mode\n","tf.config.run_functions_eagerly(False)"],"metadata":{"id":"lEtlY0p9fi1t"},"id":"lEtlY0p9fi1t","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","Graph tracing only captures TensorFlow operations into a graph and not print statements etc.\n","\n","---"],"metadata":{"id":"smJeM_JNgZeh"},"id":"smJeM_JNgZeh"},{"cell_type":"code","source":["@tf.function\n","def get_MSE(y_true, y_pred):\n","  print('Calculating MSE')\n","  return tf.reduce_mean((y_true - y_pred)**2)\n","\n","y_true = tf.random.uniform([5], maxval=10, dtype=tf.int32)\n","y_pred = tf.random.uniform([5], maxval=10, dtype=tf.int32)\n","\n","# Execution in graph mode captures the print statement only once\n","print(get_MSE(y_true, y_pred))\n","print(get_MSE(y_true, y_pred))\n","print(get_MSE(y_true, y_pred))\n","\n","# Switching to eager mode will capture the print statement all 3 times\n","tf.config.run_functions_eagerly(True)\n","print(get_MSE(y_true, y_pred))\n","print(get_MSE(y_true, y_pred))\n","print(get_MSE(y_true, y_pred))\n","\n","# Switch back to graph mode\n","tf.config.run_functions_eagerly(False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r2HupaBxglnx","executionInfo":{"status":"ok","timestamp":1709122222603,"user_tz":-330,"elapsed":447,"user":{"displayName":"S N S Acharya","userId":"14786945180387920086"}},"outputId":"20a17115-1ff6-4ce9-dbf3-276539f1bd35"},"id":"r2HupaBxglnx","execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Calculating MSE\n","tf.Tensor(17, shape=(), dtype=int32)\n","Calculating MSE\n","tf.Tensor(17, shape=(), dtype=int32)\n","Calculating MSE\n","tf.Tensor(17, shape=(), dtype=int32)\n","Calculating MSE\n","tf.Tensor(17, shape=(), dtype=int32)\n","Calculating MSE\n","tf.Tensor(17, shape=(), dtype=int32)\n","Calculating MSE\n","tf.Tensor(17, shape=(), dtype=int32)\n"]}]},{"cell_type":"markdown","source":["---\n","\n","Graph mode cprresponds to non-strict execution which means only those operations necessary to produce the observable effects are executed.\n","\n","In contrast, in eager execution mode, all of the program operations, needed or not, are stepped through and executed.\n","\n","---"],"metadata":{"id":"AETH_kyihSa1"},"id":"AETH_kyihSa1"},{"cell_type":"code","source":["x = tf.constant([1., 2., 3.])\n","\n","def unused_func(x):\n","  # Get index 3 will fail\n","  tf.gather(x, [3]) # unused operation not connected to what function is returning\n","  return x\n","\n","tf_unused_func = tf.function(unused_func)\n","\n","try:\n","  print(tf_unused_func(x))\n","except tf.errors.InvalidArgumentError as e:\n","  # Unused operations are not run during graph execution so no error is raised.\n","  print(f'{type(e).__name__}: {e}')\n","\n","try:\n","  print(unused_func(x))\n","except tf.errors.InvalidArgumentError as e:\n","  # All operations are run during eager execution so an error is raised.\n","  print(f'{type(e).__name__}: {e}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-iC3KAtHhpo6","executionInfo":{"status":"ok","timestamp":1709122242456,"user_tz":-330,"elapsed":425,"user":{"displayName":"S N S Acharya","userId":"14786945180387920086"}},"outputId":"99766f77-d9f8-487b-bd86-5ca6c651d8bf"},"id":"-iC3KAtHhpo6","execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32)\n","InvalidArgumentError: {{function_node __wrapped__GatherV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[0] = 3 is not in [0, 3) [Op:GatherV2]\n"]}]},{"cell_type":"markdown","source":["**tf.function best practices**:\n","\n","- Toggle between eager and graph execution early and often with tf.config.run_functions_eagerly to pinpoint if/ when the two modes diverge.\n","- Create tf.Variables outside the Python function and modify them on the inside. The same goes for objects that use tf.Variable, like tf.keras.layers, tf.keras.Models and tf.keras.optimizers.\n","- Avoid writing functions that depend on outer Python variables, excluding tf.Variables and Keras objects. Learn more in Depending on Python global and free variables of the tf.function guide.\n","- Prefer to write functions which take tensors and other TensorFlow types as input.\n","- Include as much computation as possible under a tf.function to maximize the performance gain. For example, decorate a whole training step or the entire training loop which runs faster under tf.function."],"metadata":{"id":"OusqMQE1n_Ax"},"id":"OusqMQE1n_Ax"},{"cell_type":"markdown","source":["---\n","\n","tf.function usually improves the performance of your code, but the amount of speed-up depends on the kind of computation you run. Small computations can be dominated by the overhead of calling a graph. You can measure the difference in performance like the example below where we multiply a matrix 100 times by itself, and repeat that operation 1000 times first using eager execution and then using graph execution:\n","\n","---"],"metadata":{"id":"LIiCTYpbojnH"},"id":"LIiCTYpbojnH"},{"cell_type":"code","source":["x = tf.random.uniform(shape=[10, 10], minval=-1, maxval=2, dtype=tf.dtypes.int32)\n","\n","def power(x, y):\n","  result = tf.eye(10, dtype=tf.dtypes.int32)\n","  for _ in range(y):\n","    result = tf.matmul(x, result)\n","  return result\n","\n","print(\"Eager execution:\", timeit.timeit(lambda: power(x, 100), number=1000), \"seconds\")\n","\n","tf_power = tf.function(power)\n","print(\"Graph execution:\", timeit.timeit(lambda: tf_power(x, 100), number=1000), \"seconds\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aS9oxqKFolqo","executionInfo":{"status":"ok","timestamp":1709122606920,"user_tz":-330,"elapsed":10609,"user":{"displayName":"S N S Acharya","userId":"14786945180387920086"}},"outputId":"357c55c9-e224-4637-d781-8fbe229c7e3a"},"id":"aS9oxqKFolqo","execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["Eager execution: 9.064996064999832 seconds\n","Graph execution: 1.0679514459998245 seconds\n"]}]},{"cell_type":"markdown","source":["---\n","\n","When is a tf.function tracing?\n","\n","---"],"metadata":{"id":"qfGjkRxspseL"},"id":"qfGjkRxspseL"},{"cell_type":"code","source":["x = tf.constant(2)\n","\n","@tf.function\n","def trace_me(x):\n","  print(\"Tracing!\") # An eager-only side effect.\n","  return x * x + tf.constant(2)\n","\n","# Tracing happens here\n","print(trace_me(x))\n","\n","# No tracing happens here\n","print(trace_me(x+1))\n","\n","# Retracing happens again because new Python arguments as input, such as the\n","# one below will also trigger the creation of a new graph which will result\n","# in extra tracing\n","print(trace_me(3))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kQf7Ck_ept9E","executionInfo":{"status":"ok","timestamp":1709122950141,"user_tz":-330,"elapsed":460,"user":{"displayName":"S N S Acharya","userId":"14786945180387920086"}},"outputId":"d721b030-c289-4eee-f0ba-b7012fd9c1f4"},"id":"kQf7Ck_ept9E","execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Tracing!\n","tf.Tensor(6, shape=(), dtype=int32)\n","tf.Tensor(11, shape=(), dtype=int32)\n","Tracing!\n","tf.Tensor(11, shape=(), dtype=int32)\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}